{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Script to scrape published data from NHSD webpages and output a compiled and procesed CSV\n",
    "### of FTE days available and FTE days lost by staff group and organisation\n",
    "### Takes up to 10 minutes to run\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Allows unverified SSLs\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# The monthly publication of sickness absences sometimes vary in format (sometimes monthly \"provisional\", sometimes just monthly, sometimes quarterly)\n",
    "# These three base URLs pick up on all variations. The code iterates through all possible URL formats for each month (and quarter). Where an invalid\n",
    "# URL is created, the code will output \"Failed to access [URL]\", where it is valid it will output \"Downloaded and parsed: [URL]\". All data about \n",
    "# failed/successful access is outputted in a seperate CSV.\n",
    "\n",
    "base_urls = [\n",
    "    \"https://digital.nhs.uk/data-and-information/publications/statistical/nhs-sickness-absence-rates/{month}-{year}-provisional-statistics\",\n",
    "    \"https://digital.nhs.uk/data-and-information/publications/statistical/nhs-sickness-absence-rates/{month}-{year}\",\n",
    "    \"https://digital.nhs.uk/data-and-information/publications/statistical/nhs-sickness-absence-rates/{month1}-{year1}-to-{month2}-{year2}-provisional-statistics\"\n",
    "]\n",
    "\n",
    "accessed_data = []\n",
    "dfs = []\n",
    "\n",
    "## Function to get quarterly month values\n",
    "\n",
    "def get_month_range_quarterly(month):\n",
    "    quarters = {\n",
    "        \"january\": (\"january\", \"march\"),\n",
    "        \"april\": (\"april\", \"june\"),\n",
    "        \"july\": (\"july\", \"september\"),\n",
    "        \"november\": (\"november\", \"december\")\n",
    "    }\n",
    "    return quarters.get(month, (None, None))\n",
    "\n",
    "## Iterates over years and months - specify years in range (remember need to +1 to upper range)\n",
    "\n",
    "for year in range(2018, 2024):\n",
    "    for month in range(1, 13):\n",
    "        month_name = datetime(year, month, 1).strftime('%B').lower()\n",
    "\n",
    "        for base_url in base_urls:\n",
    "            ## Gets correct year for quarter\n",
    "            if \"{month1}-{year1}-to-{month2}-{year2}\" in base_url:\n",
    "                start_month, end_month = get_month_range_quarterly(month_name)\n",
    "                if not start_month:\n",
    "                    continue\n",
    "                month1 = start_month\n",
    "                month2 = end_month\n",
    "                year1 = year\n",
    "                year2 = year\n",
    "                if end_month == \"december\":\n",
    "                    year2 += 1\n",
    "                url = base_url.format(month1=month1, year1=year1, month2=month2, year2=year2)\n",
    "            else:\n",
    "                url = base_url.format(month=month_name, year=year)\n",
    "\n",
    "            # Download the monthly webpage\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML content of the monthly webpage\n",
    "                soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                # Find all the CSV links on the monthly webpage\n",
    "                csv_links = soup.select('a[href$=\".csv\"]')\n",
    "\n",
    "                # Append the accessed webpage to the accessed_data list\n",
    "                accessed_data.append({\"URL\": url, \"Status\": \"Accessed\", \"CSV Count\": len(csv_links)})\n",
    "\n",
    "                # Iterate over the CSV links and download the files\n",
    "                for link in csv_links:\n",
    "                    csv_url = link[\"href\"]\n",
    "                    # Download the CSV file\n",
    "                    response_csv = requests.get(csv_url)\n",
    "                    if response_csv.status_code == 200:\n",
    "                        # Read the CSV data into a DataFrame\n",
    "                        df = pd.read_csv(csv_url)\n",
    "                        # Add a new column with the downloaded URL\n",
    "                        df[\"Downloaded From\"] = csv_url\n",
    "                        # Append the downloaded data to the dfs list\n",
    "                        dfs.append(df)\n",
    "                        # Append the downloaded CSV URL to the downloaded_data list\n",
    "                        accessed_data.append({\"URL\": csv_url, \"Status\": \"Downloaded\"})\n",
    "                        print(f\"Downloaded and parsed: {csv_url}\")\n",
    "                    else:\n",
    "                        # Append the failed CSV URL to the downloaded_data list\n",
    "                        accessed_data.append({\"URL\": csv_url, \"Status\": \"Failed\"})\n",
    "                        print(f\"Failed to download CSV from {csv_url}\")\n",
    "                break  # Exit the loop if CSV files were found and downloaded\n",
    "            else:\n",
    "                # Append the failed webpage to the accessed_data list\n",
    "                accessed_data.append({\"URL\": url, \"Status\": \"Failed\", \"CSV Count\": 0})\n",
    "                print(f\"Failed to access webpage: {url}\")\n",
    "\n",
    "accessed_df = pd.DataFrame(accessed_data)\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Optional: Save the accessed_df to separate CSV file\n",
    "accessed_df.to_csv(\"accessed_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'Downloaded From' for cells containing \"benchmarking\" because that picks up on\n",
    "# sickness absence benchmarking data which is in the format we want. \n",
    "absence_df = combined_df[combined_df['Downloaded From'].str.contains('benchmarking')].dropna(axis = 1, how = 'all').dropna(axis = 0, how = 'all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the 'Downloaded From' for cells containing \"REASON\" because that picks up on\n",
    "# sickness absence reason data. \n",
    "reason_df = combined_df[combined_df['Downloaded From'].str.contains('REASON')].dropna(axis = 1, how = 'all').dropna(axis = 0, how = 'all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid19_df = combined_df[combined_df['Downloaded From'].str.contains('COVID-19')].dropna(axis = 1, how = 'all').dropna(axis = 0, how = 'all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62613 entries, 0 to 62612\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Downloaded From      62613 non-null  object \n",
      " 1   DATE                 62613 non-null  object \n",
      " 2   NHSE_REGION_CODE     62613 non-null  object \n",
      " 3   NHSE_REGION_NAME     62613 non-null  object \n",
      " 4   ORG_CODE             62613 non-null  object \n",
      " 5   ORG_NAME             62613 non-null  object \n",
      " 6   FTE_DAYS_LOST        50158 non-null  float64\n",
      " 7   FTE_DAYS_AVAILABLE   50419 non-null  float64\n",
      " 8   STAFF_GROUP          62613 non-null  object \n",
      " 9   FTE_DAYS_LOST_COVID  49015 non-null  float64\n",
      " 10  ICS_CODE             43648 non-null  object \n",
      " 11  ICS_NAME             43648 non-null  object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "covid19_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 815248 entries, 0 to 815247\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   Downloaded From  815248 non-null  object \n",
      " 1   Month            815248 non-null  object \n",
      " 2   Staff group      815248 non-null  object \n",
      " 3   Type             815248 non-null  object \n",
      " 4   Reason           815248 non-null  object \n",
      " 5   FTE days         815248 non-null  float64\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 37.3+ MB\n"
     ]
    }
   ],
   "source": [
    "reason_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Downloaded From</th>\n",
       "      <th>Month</th>\n",
       "      <th>Staff group</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reason</th>\n",
       "      <th>FTE days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>All staff groups</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>3.298616e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>Professionally qualified clinical staff</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>1.778899e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>HCHS doctors</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>3.300960e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>Associate Specialist</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>8.038344e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>1.310032e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Downloaded From       Month   \n",
       "0  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...  2015-01-31  \\\n",
       "1  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...  2015-01-31   \n",
       "2  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...  2015-01-31   \n",
       "3  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...  2015-01-31   \n",
       "4  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...  2015-01-31   \n",
       "\n",
       "                               Staff group                Type       Reason   \n",
       "0                         All staff groups  FTE days available  All reasons  \\\n",
       "1  Professionally qualified clinical staff  FTE days available  All reasons   \n",
       "2                             HCHS doctors  FTE days available  All reasons   \n",
       "3                     Associate Specialist  FTE days available  All reasons   \n",
       "4                               Consultant  FTE days available  All reasons   \n",
       "\n",
       "       FTE days  \n",
       "0  3.298616e+07  \n",
       "1  1.778899e+07  \n",
       "2  3.300960e+06  \n",
       "3  8.038344e+04  \n",
       "4  1.310032e+06  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Month' column to datetime format\n",
    "reason_df['Month'] = pd.to_datetime(reason_df['Month'], errors='coerce')\n",
    "\n",
    "# Convert Month column dates to the format 'YYYY-MM-DD'\n",
    "reason_df['Month'] = reason_df['Month'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "#reason_df['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_df.rename(columns={'Month': 'Date'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\TEMP\\ipykernel_20156\\1949149587.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  absence_df['Month'] = pd.to_datetime(absence_df[ 'Month'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Month' column to datetime format\n",
    "absence_df['Month'] = pd.to_datetime(absence_df[ 'Month'], errors='coerce')\n",
    "\n",
    "# Convert Month column dates to the format 'YYYY-MM-DD'\n",
    "absence_df['Month'] = absence_df['Month'].dt.to_period('M').dt.to_timestamp()\n",
    "#absence_df['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\TEMP\\ipykernel_20156\\525794252.py:2: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  absence_df['DATE'] = pd.to_datetime(absence_df['DATE'], errors='coerce')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "[                'NaT', '2022-04-01 00:00:00', '2022-05-01 00:00:00',\n",
       " '2022-07-01 00:00:00', '2022-08-01 00:00:00', '2022-09-01 00:00:00',\n",
       " '2022-10-01 00:00:00', '2022-11-01 00:00:00', '2022-12-01 00:00:00',\n",
       " '2023-01-01 00:00:00']\n",
       "Length: 10, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'Date' column to datetime format\n",
    "absence_df['DATE'] = pd.to_datetime(absence_df['DATE'], errors='coerce')\n",
    "\n",
    "# Convert all dates to the format 'YYYY-MM-DD'\n",
    "absence_df['DATE'] = absence_df['DATE'].dt.to_period('M').dt.to_timestamp()\n",
    "absence_df['DATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'Month' and 'DATE' columns into a single column 'Date'\n",
    "absence_df['Date'] = absence_df['Month'].combine_first(absence_df['DATE'])\n",
    "\n",
    "# Drop old dates columns\n",
    "absence_df = absence_df.drop(['Month','DATE'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same thing for all columns containing same data category but different names\n",
    "columns_to_merge = {\n",
    "    'NHSE region code': 'NHSE_REGION_CODE',\n",
    "    'NHSE region name': 'NHSE_REGION_NAME',\n",
    "    'Org code': 'ORG_CODE',\n",
    "    'Org name': 'ORG_NAME',\n",
    "    'FTE days lost': 'FTE_DAYS_LOST',\n",
    "    'FTE days available': 'FTE_DAYS_AVAILABLE',\n",
    "    'Sickness absence rate (%)': 'SICKNESS_ABSENCE_RATE_PERCENT',\n",
    "    'Staff group': 'STAFF_GROUP',\n",
    "    'Cluster group': 'CLUSTER_GROUP',\n",
    "    'Benchmark group': 'BENCHMARK_GROUP',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the columns to merge\n",
    "for column, matching_column in columns_to_merge.items():\n",
    "    # Check if both columns exist in the dataframe\n",
    "    if column in absence_df.columns and matching_column in absence_df.columns:\n",
    "        # Merge the columns by filling the missing values\n",
    "        absence_df[column] = absence_df[column].fillna(absence_df[matching_column])\n",
    "\n",
    "# Drop the matching columns so only the merged column remains\n",
    "absence_df = absence_df.drop(columns_to_merge.values(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up and simplify data frame\n",
    "to_drop = ['Downloaded From','Tm End Date','ICS_CODE','ICS_NAME','HEE region code',\n",
    "         'HEE region name','Sickness absence rate (%)']\n",
    "replace_dict_region = {'South East of England':'South East',\n",
    "                'South West of England':'South West'}\n",
    "replace_dict_staff = {'All staff':'All staff groups',\n",
    "                'HCHS Doctors':'HCHS doctors (exc. junior Drs)',\n",
    "                'HCHS doctors':'HCHS doctors (exc. junior Drs)'}\n",
    "df = absence_df.sort_values('Date')\n",
    "df['NHSE region name'] = df['NHSE region name'].replace(replace_dict_region)\n",
    "df['Staff group'] = df['Staff group'].replace(replace_dict_staff)\n",
    "df.drop(to_drop,axis=1, inplace=True)\n",
    "order = ['Date','Org code','Org name','NHSE region code','NHSE region name','Cluster group','Benchmark group',\n",
    "         'Staff group','FTE days lost','FTE days available']\n",
    "df = df.drop_duplicates()\n",
    "df = df[order].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Downloaded From</th>\n",
       "      <th>Date</th>\n",
       "      <th>Staff group</th>\n",
       "      <th>Type</th>\n",
       "      <th>Reason</th>\n",
       "      <th>FTE days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All staff groups</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>3.298616e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Professionally qualified clinical staff</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>1.778899e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>HCHS doctors</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>3.300960e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Associate Specialist</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>8.038344e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://files.digital.nhs.uk/5D/B325FA/MDS_ABS...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>FTE days available</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>1.310032e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Downloaded From       Date   \n",
       "0  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS... 2015-01-01  \\\n",
       "1  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS... 2015-01-01   \n",
       "2  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS... 2015-01-01   \n",
       "3  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS... 2015-01-01   \n",
       "4  https://files.digital.nhs.uk/5D/B325FA/MDS_ABS... 2015-01-01   \n",
       "\n",
       "                               Staff group                Type       Reason   \n",
       "0                         All staff groups  FTE days available  All reasons  \\\n",
       "1  Professionally qualified clinical staff  FTE days available  All reasons   \n",
       "2                             HCHS doctors  FTE days available  All reasons   \n",
       "3                     Associate Specialist  FTE days available  All reasons   \n",
       "4                               Consultant  FTE days available  All reasons   \n",
       "\n",
       "       FTE days  \n",
       "0  3.298616e+07  \n",
       "1  1.778899e+07  \n",
       "2  3.300960e+06  \n",
       "3  8.038344e+04  \n",
       "4  1.310032e+06  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All staff groups',\n",
       " 'Ambulance staff',\n",
       " 'Associate Specialist',\n",
       " 'Central functions',\n",
       " 'Consultant',\n",
       " 'Core Training',\n",
       " 'Foundation Doctor Year 1',\n",
       " 'Foundation Doctor Year 2',\n",
       " 'HCHS doctors',\n",
       " 'Hospital Practitioner / Clinical Assistant',\n",
       " 'Hotel, property & estates',\n",
       " 'Managers',\n",
       " 'Midwives',\n",
       " 'NHS infrastructure support',\n",
       " 'Nurses & health visitors',\n",
       " 'Other and Local HCHS Doctor Grades',\n",
       " 'Other staff or those with unknown classification',\n",
       " 'Professionally qualified clinical staff',\n",
       " 'Scientific, therapeutic & technical staff',\n",
       " 'Senior managers',\n",
       " 'Specialty Doctor',\n",
       " 'Specialty Registrar',\n",
       " 'Staff Grade',\n",
       " 'Support to ST&T staff',\n",
       " 'Support to ambulance staff',\n",
       " 'Support to clinical staff',\n",
       " 'Support to doctors, nurses & midwives']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(reason_df['Staff group'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FTE days available', 'FTE days lost'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reason_df['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 815248 entries, 0 to 815247\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   Downloaded From  815248 non-null  object        \n",
      " 1   Date             815248 non-null  datetime64[ns]\n",
      " 2   Staff group      815248 non-null  object        \n",
      " 3   Type             815248 non-null  object        \n",
      " 4   Reason           815248 non-null  object        \n",
      " 5   FTE days         815248 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(4)\n",
      "memory usage: 37.3+ MB\n"
     ]
    }
   ],
   "source": [
    "reason_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_df.to_csv('sickness_absence_reason_unprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pivot the 'Type' column using pivot_table\n",
    "p_reason_df = pd.pivot_table(reason_df, index=['Date','Reason','Staff group'], columns=['Type'], values='FTE days', aggfunc='sum')\n",
    "\n",
    "# Reset the index\n",
    "p_reason_df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Type</th>\n",
       "      <th>Date</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Staff group</th>\n",
       "      <th>FTE days available</th>\n",
       "      <th>FTE days lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>All staff groups</td>\n",
       "      <td>4.947924e+08</td>\n",
       "      <td>2.314284e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>Ambulance staff</td>\n",
       "      <td>8.261049e+06</td>\n",
       "      <td>6.245611e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>Associate Specialist</td>\n",
       "      <td>1.205752e+06</td>\n",
       "      <td>3.291103e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>Central functions</td>\n",
       "      <td>4.329497e+07</td>\n",
       "      <td>1.597401e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>All reasons</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>1.965047e+07</td>\n",
       "      <td>2.375077e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Type       Date       Reason           Staff group  FTE days available   \n",
       "0    2015-01-01  All reasons      All staff groups        4.947924e+08  \\\n",
       "1    2015-01-01  All reasons       Ambulance staff        8.261049e+06   \n",
       "2    2015-01-01  All reasons  Associate Specialist        1.205752e+06   \n",
       "3    2015-01-01  All reasons     Central functions        4.329497e+07   \n",
       "4    2015-01-01  All reasons            Consultant        1.965047e+07   \n",
       "\n",
       "Type  FTE days lost  \n",
       "0      2.314284e+07  \n",
       "1      6.245611e+05  \n",
       "2      3.291103e+04  \n",
       "3      1.597401e+06  \n",
       "4      2.375077e+05  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FTE days available is only recorded for all reasons (not broken down by sickness absence reason)\n",
    "p_reason_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_reason_df.to_csv('sickness_absence_reason_unprocessed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'REF_SICK_ABSENCE_REASONS.csv'\n",
    "df_ref = pd.read_csv(url)\n",
    "df_ref.rename(columns={'Sick_Lv1_Reason':'Reason','Sick_Lv1_Description':'Description'},inplace=True) \n",
    "df_ref.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reason = pd.merge(p_reason_df, df_ref[['Reason','Description']], on='Reason',how='left')\n",
    "#df_leaver_r2 = df_reason.dropna()\n",
    "#df_leaver_r2.drop_duplicates(subset=merge_cols)\n",
    "df_reason.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reason.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reason.to_csv('sickness_absence_reason.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sickness_absence.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
