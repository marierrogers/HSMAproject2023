{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tempdir/turnover\"  # or unix / linux / mac path\n",
    "\n",
    "# Get the files from the path provided in the OP\n",
    "files_annual = Path(path).glob('*annual.csv')\n",
    "files_monthly = Path(path).glob('*monthly.csv')\n",
    "\n",
    "columns_to_merge = {\n",
    "    'Period' : 'PERIOD',\n",
    "    'Type' : 'TYPE',\n",
    "    'NHSE region code': 'NHSE_REGION_CODE',\n",
    "    'NHSE region name': 'NHSE_REGION_NAME',\n",
    "    'Org code': 'ORG_CODE',\n",
    "    'Org name': 'ORG_NAME',\n",
    "    'Org Code': 'ORG_CODE',\n",
    "    'Org Name': 'ORG_NAME',\n",
    "    'Org Type': 'ORG_TYPE',\n",
    "    'FTE days lost': 'FTE_DAYS_LOST',\n",
    "    'FTE Days Sick' : 'FTE_DAYS_LOST',\n",
    "    'FTE days available': 'FTE_DAYS_AVAILABLE',\n",
    "    'FTE Days Available' : 'FTE_DAYS_AVAILABLE',\n",
    "    'Sickness absence rate (%)': 'SICKNESS_ABSENCE_RATE_PERCENT',\n",
    "    'Staff group': 'STAFF_GROUP',\n",
    "    'Cluster group': 'CLUSTER_GROUP',\n",
    "    'Benchmark group': 'BENCHMARK_GROUP',\n",
    "    'HC':'HC',\n",
    "    'FTE':'FTE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files_annual:\n",
    "    print(f.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "df = None\n",
    "\n",
    "for f in files_annual:\n",
    "    #print(f.as_posix())\n",
    "    data = pd.read_csv(f.as_posix())\n",
    "   # print(f\"Number of rows: {len(data)}\")\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file_date'] = str(f)[17:27] # Varies depending on name\n",
    "    data.columns = [columns_to_merge.get(k,k) for k in data.columns]\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[[\"file_date\", \"PERIOD\", \"ORG_CODE\", \"ORG_NAME\", \"NHSE_REGION_CODE\", \"NHSE_REGION_NAME\", \"CLUSTER_GROUP\", \"BENCHMARK_GROUP\", \"STAFF_GROUP\", \"TYPE\", \"HC\", \"FTE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.sort_values(by='file_date', ascending = False).groupby(['PERIOD', 'ORG_NAME', 'STAFF_GROUP', 'TYPE']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date columns to date types\n",
    "# TODO\n",
    "df2['DATE'] = df2.apply(lambda x: datetime.strptime(x['PERIOD'].split(' to ')[1]+'01', \n",
    "                                '%Y%m%d') \n",
    "                               if x['TYPE'] in ('Leavers', \n",
    "                                'Joiners') else (datetime.strptime('01/'+x['PERIOD'][3:10], \n",
    "                                                                   '%d/%m/%Y') \n",
    "                                                                            if x['TYPE'] == 'Denoms' else None), \n",
    "                                                                            axis = 1) \n",
    "df2['file_date'] = pd.to_datetime(df2['file_date'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(['NHSE_REGION_NAME', 'BENCHMARK_GROUP', 'ORG_NAME', 'STAFF_GROUP', 'DATE']).apply(lambda x: \n",
    "        pd.Series({\n",
    "        'n': x.shape[0],\n",
    "        'join_HC': x.loc[x['TYPE'].str.contains('Joiners'), 'HC'].values[0] if any(x['TYPE'] == 'Joiners') else None,\n",
    "        'join_FTE': x.loc[x['TYPE'] == 'Joiners', 'FTE'].values[0] if any(x['TYPE'] == 'Joiners') else None,\n",
    "        'leave_HC': x.loc[x['TYPE'] == 'Leavers', 'HC'].values[0] if any(x['TYPE'] == 'Leavers') else None,\n",
    "        'leave_FTE': x.loc[x['TYPE'] == 'Leavers', 'FTE'].values[0] if any(x['TYPE'] == 'Leavers') else None,\n",
    "        'denom_HC': x.loc[x['TYPE'] == 'Denoms', 'HC'].values[0] if any(x['TYPE'] == 'Denoms') else None,\n",
    "        'denom_FTE': x.loc[x['TYPE'] == 'Denoms', 'FTE'].values[0] if any(x['TYPE'] == 'Denoms') else None,\n",
    "    })).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop CCGs and ICBs\n",
    "df3 = df3[df3['ORG_NAME'].str.contains(\"CCG|ICB\")==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = None\n",
    "df4 = df3.copy()\n",
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.index = df4['DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "one_year = timedelta(days=365)\n",
    "fte_avg = df4.groupby(['NHSE_REGION_NAME', 'BENCHMARK_GROUP', 'ORG_NAME', 'STAFF_GROUP']).rolling(one_year, on=\"DATE\")['denom_FTE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_avg = df4.groupby(['NHSE_REGION_NAME', 'BENCHMARK_GROUP', 'ORG_NAME', 'STAFF_GROUP']).rolling(one_year, on=\"DATE\")['denom_HC'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['AVG_FTE'] = fte_avg.reset_index()['denom_FTE']\n",
    "df4['AVG_HC'] = hc_avg.reset_index()['denom_HC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.sort_values(by=['NHSE_REGION_NAME', 'ORG_NAME', 'BENCHMARK_GROUP','DATE'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('../annual_turnover.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythondev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
