{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inactive orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "  \n",
    "# import json\n",
    "import json\n",
    "# store the URL in url as \n",
    "# parameter for urlopen\n",
    "url = \"https://directory.spineservices.nhs.uk/ORD/2-0-0/organisations?Status=Inactive&Roles=RO197,RO98&Limit=1000\"\n",
    "  \n",
    "# store the response of URL\n",
    "response = urlopen(url)\n",
    "  \n",
    "# storing the JSON response \n",
    "# from url in data\n",
    "data_json = json.loads(response.read())\n",
    "  \n",
    "# print the json response\n",
    "#print(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inactive_orgs = []\n",
    "\n",
    "for q in data_json['Organisations']:\n",
    "    inactive_orgs.append({\n",
    "        \"ORG_NAME\": q['Name'],\n",
    "        \"ORG_CODE\" : q['OrgId']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tempdir/inactive_organisations.txt\", 'w') as f:\n",
    "    json.dump(inactive_orgs, f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inactive_orgs = pd.read_json('./tempdir/inactive_organisations.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load turnover data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"tempdir/turnover\"  # or unix / linux / mac path\n",
    "\n",
    "# Get the files from the path provided in the OP\n",
    "files_annual = Path(path).glob('*annual.csv')\n",
    "files_monthly = Path(path).glob('*monthly.csv')\n",
    "\n",
    "columns_to_merge = {\n",
    "    'Period' : 'PERIOD',\n",
    "    'Type' : 'TYPE',\n",
    "    'Org code': 'ORG_CODE',\n",
    "    'Org name': 'ORG_NAME',\n",
    "    'NHSE region code': 'NHSE_REGION_CODE',\n",
    "    'NHSE region name': 'NHSE_REGION_NAME',\n",
    "    'ICS code': 'ICS_CODE',\n",
    "    'ICS name': 'ICS_NAME',\n",
    "    'Cluster group': 'CLUSTER_GROUP',\n",
    "    'Benchmark group': 'BENCHMARK_GROUP',   \n",
    "    'Staff group': 'STAFF_GROUP',\n",
    "    'HC':'HC',\n",
    "    'FTE':'FTE'\n",
    "    # 'Org Code': 'ORG_CODE',\n",
    "    # 'Org Name': 'ORG_NAME',\n",
    "    # 'Org Type': 'ORG_TYPE',\n",
    "    # 'FTE days lost': 'FTE_DAYS_LOST',\n",
    "    # 'FTE Days Sick' : 'FTE_DAYS_LOST',\n",
    "    # 'FTE days available': 'FTE_DAYS_AVAILABLE',\n",
    "    # 'FTE Days Available' : 'FTE_DAYS_AVAILABLE',\n",
    "    # 'Sickness absence rate (%)': 'SICKNESS_ABSENCE_RATE_PERCENT',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in files_annual:\n",
    "#     print(f.as_posix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat files in tempdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = list()\n",
    "df = None\n",
    "\n",
    "for f in files_annual:\n",
    "    #print(f.as_posix())\n",
    "    data = pd.read_csv(f.as_posix())\n",
    "   # print(f\"Number of rows: {len(data)}\")\n",
    "    # .stem is method for pathlib objects to get the filename w/o the extension\n",
    "    data['file_date'] = str(f)[17:27] #Â Varies depending on name\n",
    "    data.columns = [columns_to_merge.get(k,k) for k in data.columns]\n",
    "    dfs.append(data)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove regions, benchmarking etc. here and rejoin at later stage with latest ref table\n",
    "# df1 = df[[\"file_date\", \"PERIOD\", \"ORG_CODE\", \"ORG_NAME\", \"NHSE_REGION_CODE\", \n",
    "#           \"NHSE_REGION_NAME\", \"CLUSTER_GROUP\", \"BENCHMARK_GROUP\", \"STAFF_GROUP\", \n",
    "#           \"TYPE\", \"HC\", \"FTE\"]]\n",
    "\n",
    "df1 = df[[\"file_date\", \"PERIOD\", \"ORG_CODE\", \"STAFF_GROUP\", \n",
    "          \"TYPE\", \"HC\", \"FTE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.sort_values(by='file_date', \n",
    "                      ascending = False).groupby(['PERIOD', 'ORG_CODE',\n",
    "                        'STAFF_GROUP', 'TYPE']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date columns to date types\n",
    "# set leavers and joiners date to be the \"from\" date in original col\n",
    "# correct date so that it is always first of the month\n",
    "df2['DATE'] = df2.apply(lambda x: datetime.strptime(x['PERIOD'].split(' to ')[1]+'01', \n",
    "                                '%Y%m%d') \n",
    "                               if x['TYPE'] in ('Leavers', \n",
    "                                'Joiners') else (datetime.strptime('01/'+x['PERIOD'][3:10], \n",
    "                                                                   '%d/%m/%Y') \n",
    "                                                                            if x['TYPE'] == 'Denoms' else None), \n",
    "                                                                            axis = 1) \n",
    "df2['file_date'] = pd.to_datetime(df2['file_date'], yearfirst = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(['ORG_CODE', 'STAFF_GROUP', 'DATE']).apply(lambda x: \n",
    "        pd.Series({\n",
    "        'n': x.shape[0],\n",
    "        'join_HC': x.loc[x['TYPE'].str.contains('Joiners'), 'HC'].values[0] if any(x['TYPE'] == 'Joiners') else None,\n",
    "        'join_FTE': x.loc[x['TYPE'] == 'Joiners', 'FTE'].values[0] if any(x['TYPE'] == 'Joiners') else None,\n",
    "        'leave_HC': x.loc[x['TYPE'] == 'Leavers', 'HC'].values[0] if any(x['TYPE'] == 'Leavers') else None,\n",
    "        'leave_FTE': x.loc[x['TYPE'] == 'Leavers', 'FTE'].values[0] if any(x['TYPE'] == 'Leavers') else None,\n",
    "        'denom_HC': x.loc[x['TYPE'] == 'Denoms', 'HC'].values[0] if any(x['TYPE'] == 'Denoms') else None,\n",
    "        'denom_FTE': x.loc[x['TYPE'] == 'Denoms', 'FTE'].values[0] if any(x['TYPE'] == 'Denoms') else None,\n",
    "    })).reset_index()\n",
    "\n",
    "# 10 min runtime MR work laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_ref = pd.read_csv('../REF_ORGANISATION.csv')\n",
    "\n",
    "# # keep only first five columns\n",
    "# org_ref = org_ref.iloc[:,0:5]\n",
    "\n",
    "# # rename columns\n",
    "# org_ref.columns = ['ORG_CODE', 'ORG_CODE_USE', 'ORG_NAME_LEGACY',\n",
    "#                     'ORG_NAME', 'ORG_STATUS']\n",
    "\n",
    "# # keep only org_code and org_status\n",
    "# org_ref = org_ref[['ORG_CODE', 'ORG_STATUS']]\n",
    "\n",
    "# org_ref.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # join org_ref to df3\n",
    "# df4 = pd.merge(df3, org_ref, how='left', on=['ORG_CODE'])\n",
    "\n",
    "# df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show unique org_status values\n",
    "# df4['ORG_STATUS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop organisations where org_status is not open\n",
    "#df5 = df4[df4['ORG_STATUS'] == 'Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inactive_orgs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge inactive dataframe\n",
    "#df4 = pd.merge(df3, inactive_orgs, on='ORG_CODE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orgs_pre_filter = df4['ORG_CODE'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Filter out inactive organizations\n",
    "# df4 = df4[~df4['ORG_NAME'].notna()].copy()\n",
    "# df4.drop(columns='ORG_NAME', inplace=True)\n",
    "# # how many orgs were filtered out?\n",
    "# orgs_post_filter = df4['ORG_CODE'].nunique()\n",
    "# n_orgs_filtered = orgs_pre_filter - orgs_post_filter\n",
    "# print(f\"Number of inactive organizations filtered out: {n_orgs_filtered}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with latest org list\n",
    "# ref table with org information\n",
    "url_ref_org = '../REF_ORGANISATION.csv'\n",
    "ref_org = pd.read_csv(url_ref_org)\n",
    "\n",
    "ref_org = ref_org.drop(['Org_Code_For_Join','Org_Open_Date',\n",
    "                        'Org_Region_Code',\n",
    "                        'Org_System_Code','Org_ICB_Name',\n",
    "                        'Org_Close_Date', 'Org_Name','Org_Type','Org_Post_Code',\n",
    "                        'Legacy_Org_Close_Date','UDALFileID','Org_System_Name',\n",
    "                        ' NHS Provider flag ',' Total WTE recorded '],axis=1)\n",
    "\n",
    "ref_org.rename(columns={'Org_Code_For_Use':'ORG_CODE','Org_Type_Grouped':'ORG_TYPE',\n",
    "                        'Org_Name_For_Use':'ORG_NAME',\n",
    "                        'Org_Region_Name':'region_name'},inplace=True)\n",
    "\n",
    "ref_org.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# org reference data merge\n",
    "df5 = pd.merge(df3, ref_org, on=['ORG_CODE'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop where org status is not open\n",
    "df5 = df5[df5['Org_Status'] == 'Open']\n",
    "\n",
    "# drop org status column\n",
    "df5 = df5.drop(['Org_Status'], axis=1)\n",
    "\n",
    "# Drop ICBs\n",
    "df5 = df5[~df5['ORG_TYPE'].isin(['INTEGRATED CARE BOARD'])]\n",
    "\n",
    "# Drop NAN org types\n",
    "df5 = df5.dropna(subset=['ORG_TYPE'])\n",
    "\n",
    "# cut rows where denom_FTE is null or 0 - no staff in post for that group/org/period\n",
    "df5 = df5[df5['denom_FTE'] != 0]\n",
    "df5 = df5[df5['denom_FTE'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = None\n",
    "df6 = df5.copy()\n",
    "df6.sort_values('DATE')\n",
    "df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['denom_FTE_12'] = df6.sort_values(by=['DATE']).groupby(['ORG_CODE','STAFF_GROUP'])['denom_FTE'].shift(12)\n",
    "df6['denom_HC_12'] = df6.sort_values(by=['DATE']).groupby(['ORG_CODE','STAFF_GROUP'])['denom_HC'].shift(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['denom_FTE_mean'] = df6[['denom_FTE', 'denom_FTE_12']].mean(axis=1)\n",
    "df6['denom_HC_mean'] = df6[['denom_HC', 'denom_HC_12']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename DATE column to month_year\n",
    "df6.rename(columns={'DATE':'month_year'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5[(df5['ORG_NAME']=='Yorkshire Ambulance Service NHS Trust') & (df5['STAFF_GROUP']=='All staff groups') & (df5['DATE'].dt.month == 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df7.sort_values(by=['ORG_CODE','month_year'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.to_csv('../annual_turnover.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythondev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
