{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to scrape published data from NHSD webpages and output a compiled and procesed CSV of FTE days available and FTE days lost by staff group and organisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_url = 'https://digital.nhs.uk/data-and-information/publications/statistical/nhs-sickness-absence-rates/'\n",
    "file_source_url = 'https://digital.nhs.uk'\n",
    "\n",
    "response = requests.get(check_url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "past_links = soup.find( id=\"past-publications\").find_all(href=re.compile(\"publications/statistical/nhs-sickness-absence-rates/\"))\n",
    "latest_link = soup.find( id=\"latest-statistics\").find_all(href=re.compile(\"publications/statistical/nhs-sickness-absence-rates/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_links.append(latest_link[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sub_url(thesoup, data_type):\n",
    "    test = False\n",
    "\n",
    "    if test:\n",
    "        print(f\"data type is: {data_type}\")\n",
    "        #print(soup)\n",
    "        \n",
    "    csv_search = thesoup.find_all(href=re.compile(\"\\.csv$\"))\n",
    "    if test:\n",
    "        print(csv_search)\n",
    "\n",
    "    xls_search = thesoup.find_all(href=re.compile(\"\\.xlsx$\"))\n",
    "\n",
    "    if test:\n",
    "        print(xls_search)\n",
    "        \n",
    "    result = [x['href'] for x in csv_search if data_type in x['href'].lower()]\n",
    "    if len(result) == 0:\n",
    "        result = [x['href'] for x in xls_search if data_type in x['href'].lower()]\n",
    "    try:\n",
    "        return(result)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_stats_urls(url_string, file_source_url, data_types):\n",
    "    test = False\n",
    "    \n",
    "    x = url_string.split('/')\n",
    "    if test:\n",
    "        print(x[-1])\n",
    "\n",
    "    date_string = x[-1]\n",
    "    regex_date_string = [m.group() for m in re.finditer(\"((january|february|march|april|may|june|july|august|september|october|november|december)-\\d{4})\", date_string)]\n",
    "\n",
    "    if test:\n",
    "        print(regex_date_string)\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    try:\n",
    "        # Retrieve find date, which takes account of URLs with a date range within\n",
    "        formatted_date = datetime.strptime(regex_date_string[-1], \"%B-%Y\")\n",
    "        if test:\n",
    "            print(formatted_date)\n",
    "        full_url = file_source_url+url_string\n",
    "        #print(full_url)\n",
    "        response = requests.get(full_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        result_list = []\n",
    "\n",
    "        for data_type in data_types:\n",
    "            if test:\n",
    "                print(f\"checking {data_type}\")\n",
    "            dt = retrieve_sub_url(soup, data_type)\n",
    "            \n",
    "            if test:\n",
    "                print(dt)\n",
    "                \n",
    "            result_list.append(dt)\n",
    "            \n",
    "        dictionary = dict(zip(data_types, result_list))\n",
    "        dictionary.update({\n",
    "            'the_date': formatted_date\n",
    "        })\n",
    "\n",
    "        #print(dictionary)\n",
    "        return dictionary\n",
    "    except:\n",
    "        print('Could not format date')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#past_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "# reason_stats_urls_list = []\n",
    "# test_links_href  = \"/data-and-information/publications/statistical/nhs-sickness-absence-rates/nhs-sickness-absence-rates-february-2017\"\n",
    "\n",
    "# get_url = retrieve_stats_urls(test_links_href, file_source_url, [\"reason\", \"rate\", \"covd\"])\n",
    "# print(get_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_urls_list = []\n",
    "\n",
    "for link in past_links:\n",
    "    #print(link['href'])\n",
    "    # NOTE: Absence by reason not available before April 2019\n",
    "    get_urls = retrieve_stats_urls(link['href'], file_source_url, [\"reason\", \"rate\", \"covid\", \"benchmark\"])\n",
    "    if get_urls is not None:\n",
    "        stats_urls_list.append(get_urls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refactoring = time of 41.6s down from 2minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory names\n",
    "directories = ['covid', 'benchmark', 'reason', 'rate']\n",
    "\n",
    "# Specify the parent directory (tempdir) in the working directory\n",
    "parent_directory = 'tempdir'\n",
    "\n",
    "# # Check if the parent directory exists, and if not, create it\n",
    "if not os.path.exists(parent_directory):\n",
    "    os.mkdir(parent_directory)\n",
    "\n",
    "# Create the subdirectories if they do not exist\n",
    "for directory in directories:\n",
    "    directory_path = os.path.join(parent_directory, directory)\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.mkdir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats_urls_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats_urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_url(url_to_file, thedate, folder):\n",
    "\n",
    "    # Set suffix for downloaded file\n",
    "    suffix = \"csv\"\n",
    "    if \"xlsx\" in url_to_file.lower():\n",
    "        suffix = \"xlsx\"\n",
    "\n",
    "    # Set filename\n",
    "    \n",
    "    file_name = \"tempdir\"\n",
    "    additional_type = \"\"\n",
    "\n",
    "    if folder == 'rate':\n",
    "        rate_type = \"-monthly\"\n",
    "        if \"annual\" in url_to_file.lower():\n",
    "            rate_type = \"-annual\"\n",
    "        elif \"quarterly\" in url_to_file.lower():\n",
    "            rate_type = '-quarterly'\n",
    "        additional_type = rate_type\n",
    "    elif folder == \"reason\" and \"mds\" in url_to_file.lower():\n",
    "        additional_type = '-mds'\n",
    "\n",
    "    file_name = file_name + \"/\" + folder + \"/\" + thedate.strftime(\"%Y-%m-%d\") + \"-\" + folder + additional_type + \".\" + suffix\n",
    "\n",
    "    response = requests.get(url_to_file)\n",
    "\n",
    "    with open(file_name, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in stats_urls_list:\n",
    "    #print(link['href'])\n",
    "    # NOTE: Absence by reason not available before April 2019\n",
    "    if len(m['reason']) > 0:\n",
    "        for i in m['reason']:\n",
    "            download_url(i, m['the_date'], \"reason\")\n",
    "    if len(m['rate']) > 0:\n",
    "        for i in m['rate']:\n",
    "            download_url(i, m['the_date'], \"rate\")\n",
    "    if len(m['covid']) > 0:\n",
    "        for i in m['covid']:\n",
    "            download_url(i, m['the_date'], \"covid\")\n",
    "    if len(m['benchmark']) > 0:\n",
    "        for i in m['benchmark']:\n",
    "            download_url(i, m['the_date'], \"benchmark\")\n",
    "\n",
    "# About a minute to download all files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
